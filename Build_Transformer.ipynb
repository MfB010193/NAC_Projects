{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9fef9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all the nuccesary libraries and functions are imported\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "from torch.nn import LayerNorm\n",
    "from torch.utils.data import dataset, dataloader\n",
    "print('all the nuccesary libraries and functions are imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bf34249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set different hiperparameters\n",
    "\n",
    "class HParams:\n",
    "    block_size: int = 128\n",
    "    n_layers: int = 6\n",
    "    n_heads: int = 8\n",
    "    d_model: int = 512\n",
    "    d_ff: int= 2048\n",
    "    dropout: float =0.1\n",
    "    emb_dropout: float = 0.0\n",
    "    lr: float = 3e-4\n",
    "    weight_decay: float = 1e-1\n",
    "    betas: tuple = (0.9, 0.95)\n",
    "    batch_size: int = 64\n",
    "    max_iters: int = 10000\n",
    "    eval_interval: int = 500\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    seed: int = 42\n",
    "    grad_clip: float = 1.0\n",
    "    top_k: int = 40\n",
    "    temperature: float = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c90f64ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ea0941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(text):\n",
    "    chars = sorted(list(set(text)))\n",
    "    stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "    itos = {i:ch for ch,i in stoi.items()}\n",
    "    return stoi, itos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd60f161",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, block_size, dropout):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = d_model // n_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        self.qkv = nn.Linear(d_model, 3 * d_model)\n",
    "        self.proj = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # causal mask will be created on the fly in forward (efficient for different devices)\n",
    "        self.register_buffer(\"mask\", torch.tril(torch.ones(block_size, block_size)).unsqueeze(0).unsqueeze(0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
